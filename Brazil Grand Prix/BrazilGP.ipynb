{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4969c54a-7241-44da-b3d0-83568913b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (527.21 MB) C:\\Users\\nitan\\AppData\\Local\\Temp\\fastf1\n",
      "core           INFO \tLoading data for S√£o Paulo Grand Prix - Practice 1 [v3.6.0]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "core        WARNING \tNo result data for this session available on Ergast! (This is expected for recent sessions)\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '5', '6', '10', '12', '14', '16', '18', '22', '23', '27', '30', '31', '43', '44', '55', '63', '81', '87']\n",
      "core           INFO \tLoading data for S√£o Paulo Grand Prix - Qualifying [v3.6.0]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tNo lap data for driver 5\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 5)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '12', '16', '81', '6', '63', '30', '87', '10', '27', '14', '23', '44', '18', '55', '1', '31', '43', '22', '5']\n",
      "core           INFO \tLoading data for S√£o Paulo Grand Prix - Race [v3.6.0]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tNo lap data for driver 23\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 23)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '31', '10', '63', '16', '4', '22', '81', '30', '44', '11', '50', '77', '14', '24', '55', '43', '23', '18', '27']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 173\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Apply normalization (scales features to range [0, 1])\u001b[39;00m\n\u001b[0;32m    172\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m--> 173\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m    174\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m    175\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X)  \u001b[38;5;66;03m# Normalize all data for final predictions\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# load the 2025 Hungarian free practice & 2024 race session data\n",
    "FP1_2025 = fastf1.get_session(2025, 'Brazil Grand Prix', 'FP1')\n",
    "#FP2_2025 = fastf1.get_session(2025, 'Mexico Grand Prix', 'FP2')\n",
    "#FP3_2025 = fastf1.get_session(2025, 'Mexico Grand Prix', 'FP3')\n",
    "Quali_2025 = fastf1.get_session(2025, 'Brazil Grand Prix', 'Q')\n",
    "Race_2024 = fastf1.get_session(2024, 'Brazil Grand Prix', 'R')\n",
    "FP1_2025.load()\n",
    "#FP2_2025.load()\n",
    "#FP3_2025.load()\n",
    "Quali_2025.load()\n",
    "Race_2024.load()\n",
    "\n",
    "# extracting the required data\n",
    "FP1_laps = FP1_2025.laps[[\"Driver\", \"LapTime\", \"SpeedST\", \"Compound\"]].copy()\n",
    "#FP2_laps = FP2_2025.laps[[\"Driver\", \"LapTime\", \"SpeedST\", \"Compound\"]].copy()\n",
    "#FP3_laps = FP3_2025.laps[[\"Driver\", \"LapTime\", \"SpeedST\", \"Compound\"]].copy()\n",
    "Quali_laps = Quali_2025.laps[[\"Driver\", \"LapTime\", \"SpeedST\", \"Compound\"]].copy()\n",
    "Race_laps = Race_2024.laps[[\"Driver\", \"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\"]].copy()\n",
    "\n",
    "# dropping the nan values\n",
    "FP1_laps.dropna(inplace=True)\n",
    "#FP2_laps.dropna(inplace=True)\n",
    "#FP3_laps.dropna(inplace=True)\n",
    "Quali_laps.dropna(inplace=True)\n",
    "Race_laps.dropna(inplace=True)\n",
    "\n",
    "# converting all laptimes to seconds\n",
    "FP1_laps['LapTimeFP1'] = FP1_laps['LapTime'].dt.total_seconds()\n",
    "#FP2_laps['LapTimeFP2'] = FP2_laps['LapTime'].dt.total_seconds()\n",
    "#FP3_laps['LapTimeFP3'] = FP3_laps['LapTime'].dt.total_seconds()\n",
    "Quali_laps['LapTimeQuali'] = Quali_laps['LapTime'].dt.total_seconds()\n",
    "Race_laps['LapTimeRace'] = Race_laps['LapTime'].dt.total_seconds()\n",
    "\n",
    "FP1_laps.drop(['LapTime'],axis=1,inplace=True)\n",
    "#FP2_laps.drop(['LapTime'],axis=1,inplace=True)\n",
    "#FP3_laps.drop(['LapTime'],axis=1,inplace=True)\n",
    "#Quali_laps.drop(['LapTime'],axis=1,inplace=True)\n",
    "Race_laps.drop(['LapTime'],axis=1,inplace=True)\n",
    "\n",
    "def process_session_data(laps_df, session_suffix, laptime_column):\n",
    "    # copy to avoid modifying original\n",
    "    data = laps_df.copy()\n",
    "    \n",
    "    # find most used tire compound per driver\n",
    "    data['TireCount'] = data.groupby(['Driver', 'Compound'])['Compound'].transform('count')\n",
    "    max_count = data.groupby('Driver')['TireCount'].transform('max')\n",
    "    data = data[data['TireCount'] == max_count]\n",
    "    \n",
    "    # aggregate by driver and compound\n",
    "    result = data.groupby(['Driver', 'Compound']).agg({\n",
    "        'SpeedST': 'mean',\n",
    "        laptime_column: 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # rename columns\n",
    "    result.rename(columns={\n",
    "        'Compound': f'Compound{session_suffix}',\n",
    "        'SpeedST': f'SpeedST{session_suffix}',\n",
    "        laptime_column: f'LapTime{session_suffix}'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # keep one record per driver and clean up\n",
    "    return result.drop_duplicates(subset=['Driver'], keep='first').reset_index(drop=True)\n",
    "\n",
    "# apply to all sessions with correct column naming\n",
    "FP1_result = process_session_data(FP1_laps, 'FP1', 'LapTimeFP1')  \n",
    "#FP2_result = process_session_data(FP2_laps, 'FP2', 'LapTimeFP2')    \n",
    "#FP3_result = process_session_data(FP3_laps, 'FP3', 'LapTimeFP3')\n",
    "\n",
    "Quali_result = Quali_laps.groupby(['Driver', 'Compound']).agg({\n",
    "'SpeedST': 'mean',\n",
    "'LapTimeQuali': 'min'\n",
    "})\n",
    "Quali_result = Quali_result.reset_index()\n",
    "Quali_result.rename(columns={'Compound': 'CompoundQuali', 'SpeedST': 'SpeedSTQuali'}, inplace=True)\n",
    "Quali_result.drop_duplicates(subset=['Driver'],keep='first', inplace=True)\n",
    "Quali_result = Quali_result.reset_index(drop=True)\n",
    "\n",
    "# processing the race session to get the average lap time for the entire race\n",
    "Race_result = Race_laps.groupby(['Driver']).agg({'LapTimeRace': 'mean'})\n",
    "Race_result = Race_result.reset_index()\n",
    "\n",
    "# creating a feature dataframe to hold the feature columns\n",
    "feature = FP1_result.copy()\n",
    "#feature = feature.merge(FP2_result, on=\"Driver\", how=\"left\")\n",
    "#feature = feature.merge(FP1_result, on=\"Driver\", how=\"left\")\n",
    "feature = feature.merge(Quali_result, on=\"Driver\", how=\"left\")\n",
    "feature = feature.reset_index()\n",
    "feature.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "# After keeping the tires in the initial models, it seems that the tyres are not affecting the results, hence dropping the tyre features\n",
    "#feature.dropna(inplace=True)\n",
    "feature = feature.reset_index(drop=True)\n",
    "feature.drop(['CompoundFP1', 'CompoundQuali'],axis=1,inplace=True)\n",
    "\n",
    "# average change of position for the last three years in Brazil\n",
    "# '+' means positions gained & '-' means position lost\n",
    "avg_pos_chng_Brazil = {\n",
    "    'PIA' : -2.00,\n",
    "    'NOR': -4.33,\n",
    "    'HAM': 0.33,\n",
    "    'LEC': -5.33,\n",
    "    'VER': 4.33,\n",
    "    'SAI': 3.00,\n",
    "    'PER': 1.00,\n",
    "    'RUS': -3.00,\n",
    "    'TSU': -4.67,\n",
    "    'STR': -2.00,\n",
    "    'ALO': 2.67,\n",
    "    'HUL': -1.50,\n",
    "    'ALB': -4.33,\n",
    "    'BOT': 1.67,\n",
    "    'OCO': 4.67,\n",
    "    'ZHO': 2.67,\n",
    "    'GAS': 4.67\n",
    "}\n",
    "# starting position of the driver on the race day\n",
    "start_pos = {\n",
    "    'PIA' : 4.00,\n",
    "    'NOR': 1.00,\n",
    "    'HAM': 13.00,\n",
    "    'LEC': 3.00,\n",
    "    'VER': 16.00,\n",
    "    'SAI': 15.00,\n",
    "    'RUS': 6.00,\n",
    "    'TSU': 19.00,\n",
    "    'STR': 14.00,\n",
    "    'ALO': 11.00,\n",
    "    'HUL': 10.00,\n",
    "    'ALB': 12.00,\n",
    "    'OCO': 17.00,\n",
    "    'GAS': 9.00,\n",
    "    'HAD': 5.00,\n",
    "    'LAW': 7.00,\n",
    "    'ANT': 2.00,\n",
    "    'BOR':20.00,\n",
    "    'COL': 18.00,\n",
    "    'BEA': 8.00\n",
    "}\n",
    "# adding the position change data & starting position to features\n",
    "feature['AvgPosChange'] = feature['Driver'].map(avg_pos_chng_Brazil)\n",
    "feature['StartPos'] = feature['Driver'].map(start_pos)\n",
    "feature.fillna(0, inplace=True)\n",
    "\n",
    "# calculating average laptimes during all practice sessions\n",
    "feature[\"Avg_LapTime (s)\"] = (\n",
    "   ( feature[\"LapTimeFP1\"] )#+\n",
    "    #feature[\"LapTimeFP2\"] +\n",
    "    #feature[\"LapTimeFP3\"])/3\n",
    ")\n",
    "# calculates the improvement in average speed time between practice 3 and practice 1\n",
    "'''\n",
    "feature[\"Improvement (s)\"] = (\n",
    "    feature[\"LapTimeFP3\"] -\n",
    "    feature[\"LapTimeFP1\"])\n",
    "'''\n",
    "feature.drop(['SpeedSTFP1', 'LapTimeFP1', 'SpeedSTQuali'],axis=1,inplace=True)\n",
    "\n",
    "feature = feature.merge(Race_result, on=\"Driver\", how=\"left\")\n",
    "feature['LapTimeRace'] = feature['LapTimeRace'].fillna(Race_result['LapTimeRace'].mean())\n",
    "\n",
    "# Apply normalization (scales features to range [0, 1])\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.transform(X)  # Normalize all data for final predictions\n",
    "\n",
    "# Initialize and configure XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=4500,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.001,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    min_child_weight= 4,\n",
    "    colsample_bytree=0.3,\n",
    "    subsample= 0.3\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on normalized test data\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"RMSE: {rmse:.4f} seconds\")\n",
    "print(f\"MAE: {mae:.4f} seconds\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost Feature Importance - F1 Race Lap Time Prediction')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Race Lap Time (s)')\n",
    "plt.ylabel('Predicted Race Lap Time (s)')\n",
    "plt.title('Actual vs Predicted Race Lap Times')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predictions for all drivers using normalized data\n",
    "all_predictions = xgb_model.predict(X_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Driver': feature['Driver'],\n",
    "    'Actual_RaceLapTime': feature['LapTimeRace'],\n",
    "    'Predicted_RaceLapTime': all_predictions,\n",
    "    'Difference': feature['LapTimeRace'] - all_predictions\n",
    "})\n",
    "results = results.sort_values('Predicted_RaceLapTime')\n",
    "\n",
    "# BRAZIL GP PODIUM PREDICTION SECTION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*20 + \"üèÅ BRAZIL GRAND PRIX PODIUM PREDICTION üèÅ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get top 3 drivers based on predicted lap times\n",
    "podium = results.head(3).copy()\n",
    "positions = ['ü•á WINNER', 'ü•à 2ND PLACE', 'ü•â 3RD PLACE']\n",
    "\n",
    "# Display podium predictions\n",
    "for idx in range(3):\n",
    "    driver_data = podium.iloc[idx]\n",
    "    print(f\"\\n{positions[idx]}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Driver: {driver_data['Driver']}\")\n",
    "    \n",
    "    # Format time as MM:SS.ss\n",
    "    lap_time = driver_data['Predicted_RaceLapTime']\n",
    "    minutes = int(lap_time // 60)\n",
    "    seconds = lap_time % 60\n",
    "    print(f\"Predicted Lap Time: {minutes}:{seconds:05.2f} ({lap_time:.4f}s)\")\n",
    "    \n",
    "    # Calculate gap to leader (not for winner)\n",
    "    if idx == 0:\n",
    "        print(\"Leader\")\n",
    "    else:\n",
    "        gap_to_leader = lap_time - podium.iloc[0]['Predicted_RaceLapTime']\n",
    "        print(f\"Gap to leader: +{gap_to_leader:.4f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"\\nPredictions for all drivers:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1541d05-a36b-4f42-aae6-4838f62b66ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
